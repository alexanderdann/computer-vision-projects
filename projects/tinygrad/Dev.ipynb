{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nnx import autograd\n",
    "from nnx.autograd.activations import ReLU, Softmax\n",
    "from nnx.autograd.initialisation import xavier_uniform\n",
    "from nnx.autograd.layers import Linear, Reshape, Sequential, Dropout\n",
    "from nnx.autograd.loss import Tensor, cross_entropy_loss\n",
    "from nnx.autograd.optimizer import SGD\n",
    "\n",
    "seed = 3\n",
    "\n",
    "autograd.rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 512\n",
    "dim = 784\n",
    "epochs = 10\n",
    "\n",
    "network = Sequential(\n",
    "    Reshape((batch_size, dim)),\n",
    "    Linear(dim, dim * 2, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 2, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 4, dim * 2, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 2, 784, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(784, num_classes, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    Softmax(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    \".\",\n",
    "    train=True,\n",
    ")  # for initial download set download=True\n",
    "validation_data = torchvision.datasets.FashionMNIST(\".\", train=False)\n",
    "\n",
    "\n",
    "def create_mnist_batch_loader(dataset, batch_size=64) -> Generator:\n",
    "    \"\"\"Create a batch loader for Fashion MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The PyTorch dataset (e.g., FashionMNIST)\n",
    "        batch_size: Number of samples per batch\n",
    "\n",
    "    Yields:\n",
    "        Generator that yields batches of (images, one-hot labels).\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    num_batches = int(dataset_size // batch_size)\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get indices for this batch\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, dataset_size)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        # Initialize batch arrays\n",
    "        actual_batch_size = len(batch_indices)\n",
    "        batch_images = np.zeros((actual_batch_size, 28, 28, 1), dtype=np.float32)\n",
    "        batch_labels = np.zeros((actual_batch_size, 10), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            image, label = dataset[idx]\n",
    "\n",
    "            # Convert PIL image to numpy array, normalize to [0,1]\n",
    "            img_array = np.array(image, dtype=np.float32)[:, :, None] / 255.0\n",
    "\n",
    "            batch_images[i] = img_array\n",
    "            batch_labels[i, label] = 1.0  # One-hot encoding\n",
    "\n",
    "        images_tensor = Tensor(batch_images, requires_grad=True)\n",
    "        labels_tensor = Tensor(batch_labels, requires_grad=False)\n",
    "\n",
    "        yield images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(network.parameters, lr=0.5, clip_value=1.0)\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    batch_pbar = tqdm(\n",
    "        create_mnist_batch_loader(training_data, batch_size=batch_size),\n",
    "        desc=\"Starting training...\",\n",
    "    )\n",
    "\n",
    "    for idx, [images, targets] in enumerate(batch_pbar):\n",
    "        output = network(images)\n",
    "        loss = cross_entropy_loss(output, targets)\n",
    "\n",
    "        batch_pbar.set_description(f\"Epoch {epoch_idx + 1}/{epochs} | Batch {idx}\")\n",
    "        batch_pbar.set_postfix({\"loss\": f\"{loss.data:.4f}\"})\n",
    "        losses.append(loss.data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    val_pbar = tqdm(\n",
    "        create_mnist_batch_loader(validation_data, batch_size=batch_size),\n",
    "        desc=\"Starting validation pass...\",\n",
    "    )\n",
    "\n",
    "    tmp = []\n",
    "    for idx, [images, targets] in enumerate(val_pbar):\n",
    "        output = network(images)\n",
    "\n",
    "        oidx = np.argmax(output.data[0])\n",
    "        tidx = np.argmax(targets.data[0])\n",
    "\n",
    "        result = oidx == tidx\n",
    "        tmp.append(result)\n",
    "\n",
    "        val_pbar.set_description(f\"Iteration {idx}\")\n",
    "        batch_pbar.set_postfix({\"accuracy\": f\"{result}\"})\n",
    "    accuracies.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
