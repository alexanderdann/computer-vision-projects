{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nnx import autograd\n",
    "from nnx.autograd.activations import ReLU, Softmax\n",
    "from nnx.autograd.initialisation import xavier_uniform\n",
    "from nnx.autograd.layers import Conv2D, Linear, Reshape, Sequential\n",
    "from nnx.autograd.loss import Tensor, cross_entropy_loss\n",
    "from nnx.autograd.optimizer import SGD\n",
    "\n",
    "seed = 3\n",
    "\n",
    "autograd.rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "network = Sequential(\n",
    "    Reshape((-1, 784)),\n",
    "    Linear(784, 784 * 2, initialiser=xavier_uniform, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(784 * 2, 784 * 4, initialiser=xavier_uniform, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(784 * 4, 784 * 2, initialiser=xavier_uniform, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(784 * 2, 784, initialiser=xavier_uniform, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(784, num_classes, initialiser=xavier_uniform, bias=True),\n",
    "    Softmax(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    \".\",\n",
    "    train=True,\n",
    ")  # for initial download set download=True\n",
    "validation_data = torchvision.datasets.FashionMNIST(\".\", train=False)\n",
    "\n",
    "\n",
    "def create_mnist_batch_loader(dataset, batch_size=64) -> Generator:\n",
    "    \"\"\"Create a batch loader for Fashion MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The PyTorch dataset (e.g., FashionMNIST)\n",
    "        batch_size: Number of samples per batch\n",
    "\n",
    "    Yields:\n",
    "        Generator that yields batches of (images, one-hot labels).\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    num_batches = (dataset_size + batch_size - 1) // batch_size  # Ceiling division\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get indices for this batch\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, dataset_size)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        # Initialize batch arrays\n",
    "        actual_batch_size = len(batch_indices)\n",
    "        batch_images = np.zeros((actual_batch_size, 28, 28, 3), dtype=np.float32)\n",
    "        batch_labels = np.zeros((actual_batch_size, 10), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            image, label = dataset[idx]\n",
    "\n",
    "            # Convert PIL image to numpy array, normalize to [0,1]\n",
    "            img_array = np.array(image, dtype=np.float32)[:, :, None] / 255.0\n",
    "\n",
    "            batch_images[i] = img_array\n",
    "            batch_labels[i, label] = 1.0  # One-hot encoding\n",
    "\n",
    "        images_tensor = Tensor(batch_images, requires_grad=True)\n",
    "        labels_tensor = Tensor(batch_labels, requires_grad=False)\n",
    "\n",
    "        yield images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "optimizer = SGD(network.parameters, lr=0.01, clip_value=1.0)\n",
    "train_loader = create_mnist_batch_loader(training_data, batch_size=batch_size)\n",
    "tqdm_iter = tqdm(train_loader, desc=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, [images, targets] in enumerate(tqdm_iter):\n",
    "    break\n",
    "\n",
    "while True:\n",
    "    output = network(images)\n",
    "\n",
    "    loss = cross_entropy_loss(output, targets)\n",
    "    msg = f\"Epoch {idx} | Current loss: {loss.data} \"\n",
    "    tqdm_iter.desc = msg\n",
    "    print(msg)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
