{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Generator\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nnx import tinygrad\n",
    "from nnx.tinygrad.activations import ReLU, Softmax\n",
    "from nnx.tinygrad.initialisation import xavier_uniform\n",
    "from nnx.tinygrad.layers import Dropout, Linear, Reshape, Sequential\n",
    "from nnx.tinygrad.loss import Tensor, cross_entropy_loss\n",
    "from nnx.tinygrad.optimizer import AdamW\n",
    "\n",
    "seed = 3\n",
    "\n",
    "tinygrad.rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Layer normalization implementation.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nnx.tinygrad.layers import Layer\n",
    "from nnx.tinygrad.tensor import Tensor\n",
    "\n",
    "\n",
    "class LayerNorm(Layer):\n",
    "    \"\"\"Implements Layer Normalization.\n",
    "\n",
    "    Normalizes the input across the features dimension (last dimension)\n",
    "    with learnable affine parameters (gamma and beta).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape: int, eps: float = 1e-5) -> None:\n",
    "        \"\"\"Initialize LayerNorm with shape parameters.\n",
    "\n",
    "        Args:\n",
    "            normalized_shape: Size of the feature dimension to normalize across\n",
    "            eps: Small constant for numerical stability\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._normalized_shape = normalized_shape\n",
    "        self._eps = eps\n",
    "\n",
    "        # Initialize parameters (gamma = scale, beta = shift)\n",
    "        self._gamma = Tensor(np.ones(normalized_shape), requires_grad=True)\n",
    "        self._beta = Tensor(np.zeros(normalized_shape), requires_grad=True)\n",
    "\n",
    "        # Register parameters so they're available for optimization\n",
    "        self._parameters.append(self._gamma)\n",
    "        self._parameters.append(self._beta)\n",
    "\n",
    "    def forward(self, inputs: Tensor) -> Tensor:\n",
    "        \"\"\"Apply layer normalization to inputs.\n",
    "\n",
    "        Args:\n",
    "            inputs: Tensor with shape (..., normalized_shape)\n",
    "\n",
    "        Returns:\n",
    "            Normalized tensor of same shape with scaling and shifting applied\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the last dimension of inputs doesn't match normalized_shape\n",
    "        \"\"\"\n",
    "        if inputs.data.shape[-1] != self._normalized_shape:\n",
    "            msg = (\n",
    "                f\"Last dimension of inputs {inputs.data.shape[-1]} \"\n",
    "                f\"doesn't match normalized_shape {self._normalized_shape}\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        # Calculate mean and variance along the feature dimension (last dimension)\n",
    "        # Keep dimensions for proper broadcasting\n",
    "        mean = np.mean(inputs.data, axis=-1, keepdims=True)\n",
    "        var = np.var(inputs.data, axis=-1, keepdims=True)\n",
    "\n",
    "        # Normalize\n",
    "        x_norm = (inputs.data - mean) / np.sqrt(var + self._eps)\n",
    "\n",
    "        # Scale and shift (broadcast gamma and beta across batch dimensions)\n",
    "        outputs_data = self._gamma.data * x_norm + self._beta.data\n",
    "\n",
    "        # Create output tensor with gradient tracking if needed\n",
    "        outputs = Tensor(\n",
    "            outputs_data,\n",
    "            requires_grad=(\n",
    "                inputs.requires_grad\n",
    "                or self._gamma.requires_grad\n",
    "                or self._beta.requires_grad\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if outputs.requires_grad:\n",
    "            # Connect the computational graph\n",
    "            outputs.prev = {inputs, self._gamma, self._beta}\n",
    "\n",
    "            def _backward() -> None:\n",
    "                if outputs.grad is not None:\n",
    "                    # Cache values for reuse in gradients\n",
    "                    inv_std = 1.0 / np.sqrt(var + self._eps)\n",
    "\n",
    "                    # Gradient for gamma\n",
    "                    if self._gamma.requires_grad:\n",
    "                        gamma_grad = np.sum(\n",
    "                            outputs.grad * x_norm,\n",
    "                            axis=tuple(range(outputs.grad.ndim - 1)),\n",
    "                        )\n",
    "                        self._gamma.grad = (\n",
    "                            gamma_grad\n",
    "                            if self._gamma.grad is None\n",
    "                            else self._gamma.grad + gamma_grad\n",
    "                        )\n",
    "\n",
    "                    # Gradient for beta\n",
    "                    if self._beta.requires_grad:\n",
    "                        beta_grad = np.sum(\n",
    "                            outputs.grad, axis=tuple(range(outputs.grad.ndim - 1))\n",
    "                        )\n",
    "                        self._beta.grad = (\n",
    "                            beta_grad\n",
    "                            if self._beta.grad is None\n",
    "                            else self._beta.grad + beta_grad\n",
    "                        )\n",
    "\n",
    "                    # Gradient for input if needed\n",
    "                    if inputs.requires_grad:\n",
    "                        # Formulas for the gradients of layer normalization\n",
    "                        N = inputs.data.shape[-1]\n",
    "                        dx_norm = outputs.grad * self._gamma.data\n",
    "\n",
    "                        # Gradient with respect to input given normalized input\n",
    "                        dvar = (\n",
    "                            -0.5\n",
    "                            * np.sum(\n",
    "                                dx_norm * (inputs.data - mean), axis=-1, keepdims=True\n",
    "                            )\n",
    "                            * inv_std**3\n",
    "                        )\n",
    "                        dmean = -np.sum(\n",
    "                            dx_norm * inv_std, axis=-1, keepdims=True\n",
    "                        ) + dvar * (-2.0 / N) * np.sum(\n",
    "                            inputs.data - mean, axis=-1, keepdims=True\n",
    "                        )\n",
    "\n",
    "                        # Final gradient for input\n",
    "                        dx = (\n",
    "                            dx_norm * inv_std\n",
    "                            + dvar * (2.0 / N) * (inputs.data - mean)\n",
    "                            + dmean * (1.0 / N)\n",
    "                        )\n",
    "                        inputs.grad = dx if inputs.grad is None else inputs.grad + dx\n",
    "\n",
    "            outputs.register_backward(_backward)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "----\n",
    "This notebook demonstrates the TinyGrad framework using the Fashion MNIST dataset. While the focus is on showing the neural network architecture implementation, the torchvision dataset loader is used for convenience. Fashion MNIST serves as a good example since the input resolution is small what eases training time for a CPU only implementation and still has 10 distinct non-trivial classes which need to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    \".\",\n",
    "    train=True,\n",
    ")  # for initial download set download=True\n",
    "validation_data = torchvision.datasets.FashionMNIST(\".\", train=False)\n",
    "\n",
    "\n",
    "def create_mnist_batch_loader(dataset, batch_size=64) -> Generator:\n",
    "    \"\"\"Create a batch loader for Fashion MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The PyTorch dataset (e.g., FashionMNIST)\n",
    "        batch_size: Number of samples per batch\n",
    "\n",
    "    Yields:\n",
    "        Generator that yields batches of (images, one-hot labels).\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    num_batches = int(dataset_size // batch_size)\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get indices for this batch\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, dataset_size)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        # Initialize batch arrays\n",
    "        actual_batch_size = len(batch_indices)\n",
    "        batch_images = np.zeros((actual_batch_size, 28, 28, 1), dtype=np.float32)\n",
    "        batch_labels = np.zeros((actual_batch_size, 10), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            image, label = dataset[idx]\n",
    "\n",
    "            # Convert PIL image to numpy array, normalize to [0,1]\n",
    "            img_array = np.array(image, dtype=np.float32)[:, :, None] / 255.0\n",
    "\n",
    "            batch_images[i] = img_array\n",
    "            batch_labels[i, label] = 1.0  # One-hot encoding\n",
    "\n",
    "        images_tensor = Tensor(batch_images)\n",
    "        labels_tensor = Tensor(batch_labels)\n",
    "\n",
    "        yield images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "--------\n",
    "Below is the definition of the neural network architecture and optimizer. The model implementation demonstrates TinyGrad's PyTorch-inspired API design. A multi-layer perceptron (MLP) architecture is used rather than convolutional layers in the initial layers for feature extraction, as the current `Conv2D` implementation prioritizes educational clarity over performance optimization.\n",
    "\n",
    "The network architecture includes several fully-connected layers with dropout regularization and ReLU activations, concluding with a softmax layer for classification. Batch size and epochs were chosen by heart and were not the product of a grid/random search for optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 256\n",
    "dim = 784\n",
    "epochs = 25\n",
    "\n",
    "network = Sequential(\n",
    "    Reshape((batch_size, dim)),\n",
    "    Linear(dim, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    LayerNorm(dim * 4),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 4, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    LayerNorm(dim * 4),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    # Linear(dim * 4, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    # LayerNorm(dim * 4),\n",
    "    # Dropout(0.3),\n",
    "    # ReLU(),\n",
    "    Linear(dim * 4, dim, initialiser=xavier_uniform, bias=True),\n",
    "    LayerNorm(dim),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim, num_classes, initialiser=xavier_uniform, bias=True),\n",
    "    LayerNorm(num_classes),\n",
    "    Dropout(0.3),\n",
    "    Softmax(),\n",
    ")\n",
    "\n",
    "optimizer = AdamW(network.parameters, lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "from nnx.tinygrad.optimizer import SGD\n",
    "\n",
    "optimizer = SGD(network.parameters, lr=1e-1, momentum=0.99, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "---------------\n",
    "To monitor training progress multiple visualization functions were implemented. These help us track:\n",
    "- Gradient flow through the network\n",
    "- Validation accuracy over time\n",
    "- Model predictions on sample data\n",
    "\n",
    "While these visualization utilities are not core to the TinyGrad implementation, they provide valuable insights into model training dynamics and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import plot_gradient_flow, plot_model_predictions, plot_validation_accuracy\n",
    "\n",
    "\n",
    "def extract_gradient_stats(model: Sequential, gradient_history: list) -> None:\n",
    "    \"\"\"Extract gradients for visualisation purposes.\"\"\"\n",
    "    grad_stats = {}\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if hasattr(layer, \"parameters\"):\n",
    "            for j, param in enumerate(layer.parameters):\n",
    "                if param.grad is not None:\n",
    "                    layer_name = f\"Layer {i}-Param {j}\"\n",
    "                    grad_stats[layer_name] = np.mean(np.abs(param.grad))\n",
    "    gradient_history.append(grad_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "---------\n",
    "In this section, we train our model on the Fashion MNIST dataset, tracking metrics throughout the process. The training loop demonstrates TinyGrad's end-to-end capabilities, from forward and backward passes to optimization and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "gradient_history = []\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    loss_per_epoch = []\n",
    "    batch_pbar = tqdm(\n",
    "        create_mnist_batch_loader(training_data, batch_size=batch_size),\n",
    "        desc=\"Starting training...\",\n",
    "    )\n",
    "\n",
    "    for idx, [images, targets] in enumerate(batch_pbar):\n",
    "        output = network(images)\n",
    "        loss = cross_entropy_loss(output, targets)\n",
    "\n",
    "        batch_pbar.set_description(f\"Epoch {epoch_idx + 1}/{epochs} | Batch {idx}\")\n",
    "        batch_pbar.set_postfix({\"loss\": f\"{loss.data:.4f}\"})\n",
    "        loss_per_epoch.append(loss.data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        extract_gradient_stats(network, gradient_history)\n",
    "\n",
    "    losses.append(loss_per_epoch)\n",
    "\n",
    "    # Valiation logic\n",
    "    val_pbar = tqdm(\n",
    "        create_mnist_batch_loader(validation_data, batch_size=batch_size),\n",
    "        desc=\"Starting validation pass...\",\n",
    "    )\n",
    "\n",
    "    tmp = []\n",
    "    for idx, [images, targets] in enumerate(val_pbar):\n",
    "        output = network(images)\n",
    "\n",
    "        predicted_classes = np.argmax(output.data, axis=1)\n",
    "        target_classes = np.argmax(targets.data, axis=1)\n",
    "        result = predicted_classes == target_classes\n",
    "\n",
    "        tmp.extend(result.tolist())\n",
    "        batch_accuracy = result.mean()\n",
    "\n",
    "        val_pbar.set_description(f\"Iteration {idx}\")\n",
    "        batch_pbar.set_postfix({\"accuracy\": f\"{batch_accuracy}\"})\n",
    "    accuracies.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gradients = plot_gradient_flow(gradient_history)\n",
    "fig_gradients.savefig(\"images/gradient_flow.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig = plot_validation_accuracy(\n",
    "    [sum(acc) / len(acc) for acc in accuracies[:5]],\n",
    "    [sum(loss) / len(loss) for loss in losses[:5]],\n",
    ")\n",
    "fig.savefig(\"images/accuracy_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "val_images, val_labels = next(\n",
    "    iter(create_mnist_batch_loader(validation_data, batch_size=batch_size)),\n",
    ")\n",
    "predictions = network(val_images)\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "fig = plot_model_predictions(\n",
    "    val_images.data,\n",
    "    val_labels.data,\n",
    "    predictions.data,\n",
    "    class_names,\n",
    "    num_samples=48,\n",
    ")\n",
    "fig.savefig(\"images/prediction_showcase.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
