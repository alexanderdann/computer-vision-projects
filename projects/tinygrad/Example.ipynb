{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderdann/Documents/Privat/Code/Repositories/computer-vision-projects/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections.abc import Generator\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from nnx import autograd\n",
    "from nnx.autograd.activations import ReLU, Softmax\n",
    "from nnx.autograd.initialisation import xavier_uniform\n",
    "from nnx.autograd.layers import Dropout, Linear, Reshape, Sequential\n",
    "from nnx.autograd.loss import Tensor, cross_entropy_loss\n",
    "from nnx.autograd.optimizer import AdamW\n",
    "\n",
    "seed = 3\n",
    "\n",
    "autograd.rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "----\n",
    "Since the focus is on the main framework we just use some dataset from torchvision. The decision was to use a dataset with small resolution to being able to quickly train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    \".\",\n",
    "    train=True,\n",
    ")  # for initial download set download=True\n",
    "validation_data = torchvision.datasets.FashionMNIST(\".\", train=False)\n",
    "\n",
    "\n",
    "def create_mnist_batch_loader(dataset, batch_size=64) -> Generator:\n",
    "    \"\"\"Create a batch loader for Fashion MNIST dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The PyTorch dataset (e.g., FashionMNIST)\n",
    "        batch_size: Number of samples per batch\n",
    "\n",
    "    Yields:\n",
    "        Generator that yields batches of (images, one-hot labels).\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_size = len(dataset)\n",
    "    indices = np.arange(dataset_size)\n",
    "    num_batches = int(dataset_size // batch_size)\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get indices for this batch\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, dataset_size)\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "        # Initialize batch arrays\n",
    "        actual_batch_size = len(batch_indices)\n",
    "        batch_images = np.zeros((actual_batch_size, 28, 28, 1), dtype=np.float32)\n",
    "        batch_labels = np.zeros((actual_batch_size, 10), dtype=np.float32)\n",
    "\n",
    "        for i, idx in enumerate(batch_indices):\n",
    "            image, label = dataset[idx]\n",
    "\n",
    "            # Convert PIL image to numpy array, normalize to [0,1]\n",
    "            img_array = np.array(image, dtype=np.float32)[:, :, None] / 255.0\n",
    "\n",
    "            batch_images[i] = img_array\n",
    "            batch_labels[i, label] = 1.0  # One-hot encoding\n",
    "\n",
    "        images_tensor = Tensor(batch_images)\n",
    "        labels_tensor = Tensor(batch_labels)\n",
    "\n",
    "        yield images_tensor, labels_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition\n",
    "--------\n",
    "Definition of the network and optimizer. While one could easily go into tuning parameters to get an optimal performance, the main goal is to show that we can actually\n",
    "train a model using the framework and combination with some optimizer such as AdamW. Using `Conv2D` was also tried for some epochs but its current implementation does not make it feasible when it comes to time to be trained until the end. An MLP is however sufficient for Demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 512\n",
    "dim = 784\n",
    "epochs = 25\n",
    "\n",
    "network = Sequential(\n",
    "    Reshape((batch_size, dim)),\n",
    "    Linear(dim, dim * 2, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 2, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 4, dim * 4, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 4, dim * 2, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(dim * 2, 784, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    ReLU(),\n",
    "    Linear(784, num_classes, initialiser=xavier_uniform, bias=True),\n",
    "    Dropout(0.3),\n",
    "    Softmax(),\n",
    ")\n",
    "\n",
    "optimizer = AdamW(network.parameters, lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "------\n",
    "We add some plots related to the training of the network such as the gradients and evalutation by looking at the validation accuracy over time and looking at some predictions. Since this has nothing to do with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import plot_gradient_flow, plot_model_predictions, plot_validation_accuracy\n",
    "\n",
    "\n",
    "def extract_gradient_stats(model: Sequential, gradient_history: list) -> None:\n",
    "    \"\"\"Extract gradients for visualisation purposes.\"\"\"\n",
    "    grad_stats = {}\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if hasattr(layer, \"parameters\"):\n",
    "            for j, param in enumerate(layer.parameters):\n",
    "                if param.grad is not None:\n",
    "                    layer_name = f\"Layer {i}-Param {j}\"\n",
    "                    grad_stats[layer_name] = np.mean(np.abs(param.grad))\n",
    "    gradient_history.append(grad_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Batch 46: : 46it [01:49,  2.48s/it, loss=1.2499]"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "gradient_history = []\n",
    "\n",
    "for epoch_idx in range(epochs):\n",
    "    loss_per_epoch = []\n",
    "    batch_pbar = tqdm(\n",
    "        create_mnist_batch_loader(training_data, batch_size=batch_size),\n",
    "        desc=\"Starting training...\",\n",
    "    )\n",
    "\n",
    "    for idx, [images, targets] in enumerate(batch_pbar):\n",
    "        output = network(images)\n",
    "        loss = cross_entropy_loss(output, targets)\n",
    "\n",
    "        batch_pbar.set_description(f\"Epoch {epoch_idx + 1}/{epochs} | Batch {idx}\")\n",
    "        batch_pbar.set_postfix({\"loss\": f\"{loss.data:.4f}\"})\n",
    "        loss_per_epoch.append(loss.data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        extract_gradient_stats(network, gradient_history)\n",
    "\n",
    "    losses.append(loss_per_epoch)\n",
    "\n",
    "    # Valiation logic\n",
    "    val_pbar = tqdm(\n",
    "        create_mnist_batch_loader(validation_data, batch_size=batch_size),\n",
    "        desc=\"Starting validation pass...\",\n",
    "    )\n",
    "\n",
    "    tmp = []\n",
    "    for idx, [images, targets] in enumerate(val_pbar):\n",
    "        output = network(images)\n",
    "\n",
    "        predicted_classes = np.argmax(output.data, axis=1)\n",
    "        target_classes = np.argmax(targets.data, axis=1)\n",
    "        result = predicted_classes == target_classes\n",
    "\n",
    "        tmp.extend(result.tolist())\n",
    "        batch_accuracy = result.mean()\n",
    "\n",
    "        val_pbar.set_description(f\"Iteration {idx}\")\n",
    "        batch_pbar.set_postfix({\"accuracy\": f\"{batch_accuracy}\"})\n",
    "    accuracies.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_gradients = plot_gradient_flow(gradient_history)\n",
    "fig_gradients.savefig(\"gradient_flow.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "fig = plot_validation_accuracy(\n",
    "    [sum(acc) / len(acc) for acc in accuracies],\n",
    "    [sum(loss) / len(loss) for loss in losses],\n",
    ")\n",
    "fig.savefig(\"accuracy_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "val_images, val_labels = next(\n",
    "    iter(create_mnist_batch_loader(validation_data, batch_size=batch_size)),\n",
    ")\n",
    "predictions = network(val_images)\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "fig = plot_model_predictions(\n",
    "    val_images.data,\n",
    "    val_labels.data,\n",
    "    predictions.data,\n",
    "    class_names,\n",
    "    num_samples=48,\n",
    ")\n",
    "fig.savefig(\"prediction_showcase.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
